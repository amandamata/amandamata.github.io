<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cache on amandamata</title>
    <link>/tags/cache/</link>
    <description>amandamata (cache)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 25 Apr 2023 07:42:55 -0300</lastBuildDate>
    
    <atom:link href="/tags/cache/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Implementing Redis caching with dotnet</title>
      <link>/post/redis/</link>
      <pubDate>Tue, 25 Apr 2023 07:42:55 -0300</pubDate>
      
      <guid>/post/redis/</guid>
      <description>&lt;p&gt;I recently had to implement a cache in an application to avoid unnecessary database queries, and that was cool. I&amp;rsquo;ve worked with Redis in the past, but I think I&amp;rsquo;ve done it the wrong way because implementing a cache with Redis has never been so cool.
&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h5 id=&#34;redis-vs-mem-cached&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#redis-vs-mem-cached&#34;&gt;
        ####
    &lt;/a&gt;
    Redis vs Mem cached
&lt;/div&gt;
&lt;/h5&gt;
&lt;p&gt;Redis is almost like a NoSql database, but it is even better because it stores data with key and values and with that, it is much easier to use it as a cache.
But the main point in this comparison is: it depends, it depends on how and how much data will be used in this cache. If you&amp;rsquo;re not sure how to store session information, MemCache makes sense. But if we&amp;rsquo;re talking about a lot of queries with bigger data, like the data we store in the database, Redis does a better job. This is because when using MemCache we are using the application&amp;rsquo;s memory to save that information, since Redis is a distributed cache, it has nothing to do with the application&amp;rsquo;s memory and it is possible to use more than one Redis database, scaling this service vertically according to demand grow up.&lt;/p&gt;
&lt;p&gt;The first time it is necessary to use the cache, the information will not be there, so it is necessary to consult the database and save it in the cache, the second time it is no longer necessary to go to the database, as the information will be in the cache. And this makes the application take less time to respond to a request, as going to the bank takes much longer than going to Redis.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://amandamata.github.io/img/redis.png&#34; alt=&#34;redis&#34;&gt;
&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h5 id=&#34;why-use&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#why-use&#34;&gt;
        ####
    &lt;/a&gt;
    Why use
&lt;/div&gt;
&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Reduce response time
Improve the end-user experience with the application, making him wait less for each click or action.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Raise availability
Since it is necessary to consume less computational resources, because it is already in the cache and I return it faster to the end user, it is then possible to have more users accessing the application simultaneously.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reduce computational costs
When we are talking about the cloud, we are reducing the consumption of lambdas and resources where the monthly bill can be cheaper.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The cost of a cache is high, so it has to be expensive on the server side to make this migration to the cache. For example, problems with the delay in response to the end customer can be costly, the end customer can simply give up using the application due to the delay, and many other problems that this delay can generate. To reduce both the cost of losing a customer and the cost of consulting the bank, the cache is then used to solve these problems.
&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h5 id=&#34;problem&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#problem&#34;&gt;
        ####
    &lt;/a&gt;
    Problem
&lt;/div&gt;
&lt;/h5&gt;
&lt;p&gt;Suppose there is an application that makes many calls to the database, but always consulting the same information, when the application was developed the developers did not think it could grow so much, and a cache was not implemented to avoid these queries to the database.
The application is for car rental for companies, and the query is simple, with each request received at the rental endpoint, it is necessary to check whether the company (document) informed in the rental request is the same as the one in the bank.
We have the scenario, let&amp;rsquo;s move on to implementation.
&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h5 id=&#34;implementation&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#implementation&#34;&gt;
        ####
    &lt;/a&gt;
    Implementation
&lt;/div&gt;
&lt;/h5&gt;
&lt;p&gt;Explanation and problem presentations, let&amp;rsquo;s implement!
For this implementation we will follow a pattern called Decorator, with this pattern it is possible to add a cache layer without adding more complexity to the repository layer, and we will follow the S principle of SOLID, [Single-responsibility principle](https:// g.co/kgs/phLumf).&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s work with dotnet, and install the packages &lt;a href=&#34;https://www.nuget.org/packages/scrutor/&#34;&gt;Scrutor&lt;/a&gt; and &lt;a href=&#34;https://www.nuget.org/packages/Microsoft.Extensions.Caching.StackExchangeRedis/7.0.5&#34;&gt;StackExchangeRedis&lt;/a&gt;&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;dotnet add package Scrutor --version 4.2.2
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;dotnet add package Microsoft.Extensions.Caching.StackExchangeRedis --version 7.0.5
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Scrutor will help us during the implementation of the caching layer without taking the single responsibility away from the repository. And StackExchangeRedis is Microsoft&amp;rsquo;s client package for using Redis with . NET.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s create a Service to handle everything related to Redis.
&lt;br/&gt;
Service:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;public class CacheService : ICacheService
{
    private readonly IDistributedCache _distributedCache;
    private readonly DistributedCacheEntryOptions _options;

    public CacheService(IDistributedCache distributedCache)
    {
        _distributedCache = distributedCache;
        _options = new DistributedCacheEntryOptions
        {
            AbsoluteExpirationRelativeToNow = 150
        };
    }

    public async Task&amp;lt;T&amp;gt; GetAsync&amp;lt;T&amp;gt;(string key)
    {
        try
        {
            var cached = await _distributedCache.GetStringAsync(key);
            if (cached is not null)
                return JsonConvert.DeserializeObject&amp;lt;T&amp;gt;(cached);
        }
        catch (Exception exception)
        { 
            // Log exception 
        }

        return default(T);
    }

    public async Task SetAsync&amp;lt;T&amp;gt;(string key, T value)
    {
        try
        {
            if (value is not null)
                await _distributedCache.SetStringAsync(key, JsonConvert.SerializeObject(value), _options);
        }
        catch (Exception exception)
        { 
            // Log exception
        }
    }

    public async Task RemoveAsync(string key)
    {
        try
        {
            await _distributedCache.RemoveAsync(key);
        }
        catch (Exception exception)
        {
            // Log exception
    	}
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s create a Repository to handle the query request to the database that will &amp;ldquo;intercept&amp;rdquo; and go first in Redis.
&lt;br/&gt;
Repository:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;public class CachedAlugatorRepository : IAlugatorRepository
{
    private readonly IAlugatorRepository _alugatorRepository;
    private readonly ICacheService _cache;

    public CachedAlugatorRepository(IAlugatorRepository alugatorRepository, ICacheService cache)
    {
        _alugatorRepository = alugatorRepository;
        _cache = cache;
    }

    public async Task&amp;lt;bool&amp;gt; DeleteAsync(string id)
    {
        var alugator = await _alugatorRepository.GetAsync(id);
        if (alugator is not null)
        {
 	    await _cache.RemoveAsync(alugator.documentId);
            return await _alugatorRepository.DeleteAsync(id);
        }

        return true;
    }

    public async Task&amp;lt;Alugator&amp;gt; GetAsync(string id)
    {
        var alugator = await _cache.GetAsync&amp;lt;Alugator&amp;gt;(id);
        if (alugator is not null)
            return alugator;

        alugator = await _alugatorRepository.GetAsync(id);

        await _cache.SetAsync&amp;lt;Alugator&amp;gt;(alugator);
        return alugator;
    }

    public async Task&amp;lt;bool&amp;gt; UpsertAsync(Alugator alugator)
    {
        await _cache.SetAsync(alugator.documentId, alugator);

        return await _alugatorRepository.UpsertAsync(alugator);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The ace in the hole is in the way we are going to configure the Repository in the Program class:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;services.AddSingleton&amp;lt;IAlugatorRepository, AlugatorRepository&amp;gt;();
services.Decorate&amp;lt;IAlugatorRepository, CachedAlugatorRepository&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This Decorate does the magic, because now when calling the AlugatorRepository the CachedAlugatorRepository will be &amp;ldquo;called&amp;rdquo; first, so every call to the repository will initially be made to the Cache Repository that contains the query logic to Redis through service. With that we keep the AlugatorRepository clean, we have a specific repository for the CachedAlugatorRepository cache and we don&amp;rsquo;t hurt the Single Responsibility Principle.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
